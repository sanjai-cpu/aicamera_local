# ğŸ§  Optimized BLIP-Based Offline Lens

A powerful **AI-driven image captioning tool** that uses your webcam and the **BLIP (Bootstrapped Language-Image Pretraining)** model to generate accurate, human-like descriptions of what the camera sees â€” all **offline** and optimized for GPU acceleration.

---

## ğŸš€ Overview

This project captures frames directly from your **webcam**, feeds them into the **Salesforce BLIP** model, and returns **descriptive captions** of the image.

It automatically detects and uses **GPU (CUDA)** if available, falls back to **CPU** otherwise, and uses **beam search** for more accurate natural-language descriptions.

---

## âœ¨ Features

- âš¡ **GPU auto-detection** (uses CUDA if available)  
- ğŸ” **Beam search decoding** for improved caption accuracy  
- ğŸ“· **Live webcam capture** â€” press a key to describe a scene  
- ğŸ§© **Optimized 384Ã—384 preprocessing** (BLIPâ€™s native input size)  
- ğŸª¶ **Offline mode** â€” once the model is downloaded, no internet required  
- ğŸ§  Uses Hugging Faceâ€™s **Salesforce/blip-image-captioning-base** model  

---

## ğŸ§° Tech Stack

- **Python 3.8+**
- **PyTorch** â€” deep learning backend  
- **Transformers** â€” BLIP model pipeline  
- **OpenCV** â€” real-time webcam capture  
- **Pillow (PIL)** â€” image handling and conversion  

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/sanjai-cpu/BLIP-Offline-Lens.git
cd BLIP-Offline-Lens
2ï¸âƒ£ Install dependencies
bash
Copy code
pip install torch torchvision torchaudio
pip install transformers
pip install opencv-python Pillow accelerate
(You may need to install torch with CUDA if you have a GPU â€” check PyTorch.org)

â–¶ï¸ Usage
Run the script
bash
Copy code
python blip_offline_lens.py
Controls
Key	Action
s	Capture an image and generate a description
q	Quit the application

Example Output
arduino
Copy code
Initializing webcam...
â³ Loading BLIP model on GPU...
âœ… Model loaded successfully.

Press 's' to capture an image and get a description.
Press 'q' to quit the application.

ğŸ“¸ Capturing image...
ğŸ“ Description: a man wearing headphones sitting in front of a computer
ğŸ§  How It Works
Webcam Input â†’ Captures a live frame via OpenCV.

Preprocessing â†’ Converts frame to RGB and resizes to 384Ã—384 (BLIPâ€™s expected input).

Model Inference â†’ BLIP generates a text description using beam search.

Output â†’ The generated caption is printed to the console.

